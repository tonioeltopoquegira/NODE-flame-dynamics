{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "a = '050'\n",
    "timeHistorySizeOfU=100\n",
    "downsampling_factor=3\n",
    "\n",
    "\n",
    "hf = h5py.File('data/Kornilov_Haeringer_all.h5', 'r')\n",
    "\n",
    "input_size = math.ceil(timeHistorySizeOfU/downsampling_factor)\n",
    "\n",
    "heat_data = np.array(hf.get('BB_A' + a+ '_Q'))\n",
    "u_data = np.array(hf.get('BB_A' + a+ '_U'))\n",
    "time_data = np.array(hf.get('BB_time'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA\n",
    "\n",
    "import autograd\n",
    "import autograd.numpy as np\n",
    "\n",
    "import scipy.integrate\n",
    "solve_ivp = scipy.integrate.solve_ivp\n",
    "\n",
    "# Build the Hamiltonian for our system\n",
    "def hamiltonian_fn(coords):\n",
    "    u, q = np.split(coords,2)\n",
    "    dens = [...] # fluid density\n",
    "    press_pert = [...] # pressure pert <-- Another input theoretically\n",
    "    c = [...] # sound speed\n",
    "    x = 0.0 # coupling coefficient, heat release and energy of the system \n",
    "    K = 0.5 * dens * u**2\n",
    "    V = 0.5 * press_pert**2 / dens * c**2 + 0.5 * x\n",
    "    return K+V\n",
    "\n",
    "# Get back the dynamics from hamiltonian\n",
    "def dynamics_fn(t, coords):\n",
    "    dcoords = autograd.grad(hamiltonian_fn)(coords)\n",
    "    dudt, dqdt = np.split(dcoords,2) # third input here (??)\n",
    "    S = np.concatenate([dqdt, -dudt], axis=-1)\n",
    "    return S\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autograd\n",
    "import autograd.numpy as np\n",
    "\n",
    "import scipy.integrate\n",
    "solve_ivp = scipy.integrate.solve_ivp\n",
    "\n",
    "def hamiltonian_fn(coords):\n",
    "    q, p = np.split(coords,2)\n",
    "    H = p**2 + q**2 # spring hamiltonian (linear oscillator)\n",
    "    return H\n",
    "\n",
    "def dynamics_fn(t, coords):\n",
    "    dcoords = autograd.grad(hamiltonian_fn)(coords)\n",
    "    dqdt, dpdt = np.split(dcoords,2)\n",
    "    S = np.concatenate([dpdt, -dqdt], axis=-1)\n",
    "    return S\n",
    "\n",
    "def get_trajectory(t_span=[0,3], timescale=10, radius=None, y0=None, noise_std=0.1, **kwargs):\n",
    "    t_eval = np.linspace(t_span[0], t_span[1], int(timescale*(t_span[1]-t_span[0])))\n",
    "    \n",
    "    # get initial state\n",
    "    if y0 is None:\n",
    "        y0 = np.random.rand(2)*2-1\n",
    "    if radius is None:\n",
    "        radius = np.random.rand()*0.9 + 0.1 # sample a range of radii\n",
    "    y0 = y0 / np.sqrt((y0**2).sum()) * radius ## set the appropriate radius\n",
    "\n",
    "    spring_ivp = solve_ivp(fun=dynamics_fn, t_span=t_span, y0=y0, t_eval=t_eval, rtol=1e-10, **kwargs)\n",
    "    q, p = spring_ivp['y'][0], spring_ivp['y'][1]\n",
    "    dydt = [dynamics_fn(None, y) for y in spring_ivp['y'].T]\n",
    "    dydt = np.stack(dydt).T\n",
    "    dqdt, dpdt = np.split(dydt,2)\n",
    "    \n",
    "    # add noise\n",
    "    q += np.random.randn(*q.shape)*noise_std\n",
    "    p += np.random.randn(*p.shape)*noise_std\n",
    "    return q, p, dqdt, dpdt, t_eval\n",
    "\n",
    "def get_dataset(seed=0, samples=50, test_split=0.5, **kwargs):\n",
    "    data = {'meta': locals()}\n",
    "\n",
    "    # randomly sample inputs\n",
    "    np.random.seed(seed)\n",
    "    xs, dxs = [], []\n",
    "    for s in range(samples):\n",
    "        x, y, dx, dy, t = get_trajectory(**kwargs)\n",
    "        xs.append( np.stack( [x, y]).T )\n",
    "        dxs.append( np.stack( [dx, dy]).T )\n",
    "        \n",
    "    data['x'] = np.concatenate(xs)\n",
    "    data['dx'] = np.concatenate(dxs).squeeze()\n",
    "\n",
    "    # make a train/test split\n",
    "    split_ix = int(len(data['x']) * test_split)\n",
    "    split_data = {}\n",
    "    for k in ['x', 'dx']:\n",
    "        split_data[k], split_data['test_' + k] = data[k][:split_ix], data[k][split_ix:]\n",
    "    data = split_data\n",
    "    return data\n",
    "\n",
    "def get_field(xmin=-1.2, xmax=1.2, ymin=-1.2, ymax=1.2, gridsize=20):\n",
    "    field = {'meta': locals()}\n",
    "\n",
    "    # meshgrid to get vector field\n",
    "    b, a = np.meshgrid(np.linspace(xmin, xmax, gridsize), np.linspace(ymin, ymax, gridsize))\n",
    "    ys = np.stack([b.flatten(), a.flatten()])\n",
    "    \n",
    "    # get vector directions\n",
    "    dydt = [dynamics_fn(None, y) for y in ys.T]\n",
    "    dydt = np.stack(dydt).T\n",
    "\n",
    "    field['x'] = ys.T\n",
    "    field['dx'] = dydt.T\n",
    "    return field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_dataset(samples= 50, test_split=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['x', 'test_x', 'dx', 'test_dx'])\n"
     ]
    }
   ],
   "source": [
    "print(data.keys())\n",
    "\n",
    "# Need dataset with x 's (possibly u, p, q), dx (possibly du, dp, dq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils \n",
    "\n",
    "import numpy as np\n",
    "import os, torch, pickle, zipfile\n",
    "import imageio, shutil\n",
    "import scipy, scipy.misc, scipy.integrate\n",
    "solve_ivp = scipy.integrate.solve_ivp\n",
    "\n",
    "\n",
    "def integrate_model(model, t_span, y0, fun=None, **kwargs):\n",
    "  def default_fun(t, np_x):\n",
    "      x = torch.tensor( np_x, requires_grad=True, dtype=torch.float32)\n",
    "      x = x.view(1, np.size(np_x)) # batch size of 1\n",
    "      dx = model.time_derivative(x).data.numpy().reshape(-1)\n",
    "      return dx\n",
    "  fun = default_fun if fun is None else fun\n",
    "  return solve_ivp(fun=fun, t_span=t_span, y0=y0, **kwargs)\n",
    "\n",
    "\n",
    "def rk4(fun, y0, t, dt, *args, **kwargs):\n",
    "  dt2 = dt / 2.0\n",
    "  k1 = fun(y0, t, *args, **kwargs)\n",
    "  k2 = fun(y0 + dt2 * k1, t + dt2, *args, **kwargs)\n",
    "  k3 = fun(y0 + dt2 * k2, t + dt2, *args, **kwargs)\n",
    "  k4 = fun(y0 + dt * k3, t + dt, *args, **kwargs)\n",
    "  dy = dt / 6.0 * (k1 + 2 * k2 + 2 * k3 + k4)\n",
    "  return dy\n",
    "\n",
    "\n",
    "def L2_loss(u, v):\n",
    "  return (u-v).pow(2).mean()\n",
    "\n",
    "\n",
    "def str2array(string):\n",
    "  lines = string.split('\\\\n')\n",
    "  names = lines[0].strip(\"b'% \\\\r\").split(' ')\n",
    "  dnames = ['d' + n for n in names]\n",
    "  names = ['trial', 't'] + names + dnames\n",
    "  data = [[float(s) for s in l.strip(\"' \\\\r,\").split( )] for l in lines[1:-1]]\n",
    "\n",
    "  return np.asarray(data), names\n",
    "\n",
    "\n",
    "def to_pickle(thing, path): # save something\n",
    "    with open(path, 'wb') as handle:\n",
    "        pickle.dump(thing, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "def from_pickle(path): # load something\n",
    "    thing = None\n",
    "    with open(path, 'rb') as handle:\n",
    "        thing = pickle.load(handle)\n",
    "    return thing\n",
    "\n",
    "\n",
    "def choose_nonlinearity(name):\n",
    "  nl = None\n",
    "  if name == 'tanh':\n",
    "    nl = torch.tanh\n",
    "  elif name == 'relu':\n",
    "    nl = torch.relu\n",
    "  elif name == 'sigmoid':\n",
    "    nl = torch.sigmoid\n",
    "  elif name == 'softplus':\n",
    "    nl = torch.nn.functional.softplus\n",
    "  elif name == 'selu':\n",
    "    nl = torch.nn.functional.selu\n",
    "  elif name == 'elu':\n",
    "    nl = torch.nn.functional.elu\n",
    "  elif name == 'swish':\n",
    "    nl = lambda x: x * torch.sigmoid(x)\n",
    "  else:\n",
    "    raise ValueError(\"nonlinearity not recognized\")\n",
    "  return nl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hamiltonian network\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "class HNN(torch.nn.Module):\n",
    "    '''Learn arbitrary vector fields that are sums of conservative and solenoidal fields'''\n",
    "    def __init__(self, input_dim, differentiable_model, field_type='solenoidal',\n",
    "                    baseline=False, assume_canonical_coords=True):\n",
    "        super(HNN, self).__init__()\n",
    "        self.baseline = baseline\n",
    "        self.differentiable_model = differentiable_model\n",
    "        self.assume_canonical_coords = assume_canonical_coords\n",
    "        self.M = self.permutation_tensor(input_dim) # Levi-Civita permutation tensor\n",
    "        self.field_type = field_type\n",
    "\n",
    "    def forward(self, x):\n",
    "        # traditional forward pass\n",
    "        if self.baseline:\n",
    "            return self.differentiable_model(x)\n",
    "\n",
    "        y = self.differentiable_model(x)\n",
    "        assert y.dim() == 2 and y.shape[1] == 2, \"Output tensor should have shape [batch_size, 2]\"\n",
    "        return y.split(1,1)\n",
    "\n",
    "    def rk4_time_derivative(self, x, dt):\n",
    "        return rk4(fun=self.time_derivative, y0=x, t=0, dt=dt)\n",
    "\n",
    "    def time_derivative(self, x, t=None, separate_fields=False):\n",
    "        '''NEURAL ODE-STLE VECTOR FIELD'''\n",
    "        if self.baseline:\n",
    "            return self.differentiable_model(x)\n",
    "\n",
    "        '''NEURAL HAMILTONIAN-STLE VECTOR FIELD'''\n",
    "        F1, F2 = self.forward(x) # traditional forward pass\n",
    "\n",
    "        conservative_field = torch.zeros_like(x) # start out with both components set to 0\n",
    "        solenoidal_field = torch.zeros_like(x)\n",
    "\n",
    "        if self.field_type != 'solenoidal':\n",
    "            dF1 = torch.autograd.grad(F1.sum(), x, create_graph=True)[0] # gradients for conservative field\n",
    "            conservative_field = dF1 @ torch.eye(*self.M.shape)\n",
    "\n",
    "        if self.field_type != 'conservative':\n",
    "            dF2 = torch.autograd.grad(F2.sum(), x, create_graph=True)[0] # gradients for solenoidal field\n",
    "            solenoidal_field = dF2 @ self.M.t()\n",
    "\n",
    "        if separate_fields:\n",
    "            return [conservative_field, solenoidal_field]\n",
    "\n",
    "        return conservative_field + solenoidal_field\n",
    "\n",
    "    def permutation_tensor(self,n):\n",
    "        M = None\n",
    "        if self.assume_canonical_coords:\n",
    "            M = torch.eye(n)\n",
    "            M = torch.cat([M[n//2:], -M[:n//2]])\n",
    "        else:\n",
    "            '''Constructs the Levi-Civita permutation tensor'''\n",
    "            M = torch.ones(n,n) # matrix of ones\n",
    "            M *= 1 - torch.eye(n) # clear diagonals\n",
    "            M[::2] *= -1 # pattern of signs\n",
    "            M[:,::2] *= -1\n",
    "    \n",
    "            for i in range(n): # make asymmetric\n",
    "                for j in range(i+1, n):\n",
    "                    M[i,j] *= -1\n",
    "        return M\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
